from TSX.utils import load_data, load_simulated_data, load_ghg_data
from TSX.models import DeepKnn, EncoderRNN
from TSX.experiments import EncoderPredictor, FeatureGeneratorExplainer, BaselineExplainer
from data_generator.true_generator_state_data import TrueFeatureGenerator
import matplotlib.pyplot as plt
import matplotlib as mpl

import torch
import os
import sys
import json
import argparse
import numpy as np
import pickle as pkl

sys.path.append(os.path.join(os.path.dirname(__file__), ".."))


def main(generator_type, data_path):
    print('********** Finding Accordance score for baseline methods **********')

    experiment = 'feature_generator_explainer'
    data = 'mimic'
    with open('config.json') as config_file:
        configs = json.load(config_file)[data]['feature_generator_explainer']
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    p_data, train_loader, valid_loader, test_loader = load_data(batch_size=configs['batch_size'], path='./data')
    feature_size = p_data.feature_size

    exp = FeatureGeneratorExplainer(train_loader, valid_loader, test_loader, feature_size, patient_data=p_data,
                                    generator_hidden_size=configs['encoding_size'], prediction_size=1,
                                    historical=(configs['historical'] == 1), generator_type=generator_type, data=data,
                                    experiment=experiment + '_' + generator_type)

    exp.generator.load_state_dict(torch.load(os.path.join('./ckpt/%s/%s.pt' % ('mimic', generator_type))))
    baselines = ['FFC','AFO','FO']
    testset = list(exp.test_loader.dataset)
    test_signals = torch.stack(([x[0] for x in testset])).to(device)

    sum_matrix = np.zeros((3,3))
    top_n = 6
    count = 0

    for sample_ID in range(len(testset)):
        signal = test_signals[sample_ID]
        matrix = np.zeros((3,3))
        top_signals = np.zeros((3,signal.shape[0]))
        result_path = data_path + str(data) + '/results_%s.pkl' % str(sample_ID)
        if not os.path.exists(result_path):
            continue
        with open(result_path, 'rb') as f:
            arr = pkl.load(f)

        count += 1
        # Read importance scores generated by each methods and pick the top n
        ffc_importance = arr['FFC']['imp'].max(axis=1)
        afo_importance = arr['AFO']['imp'].max(axis=1)
        fo_importance = arr['Suresh_et_al']['imp'].max(axis=1)
        top = ffc_importance.argsort()[-1*top_n:][::-1]
        top_signals[0,top] = 1
        top = afo_importance.argsort()[-1 * top_n:][::-1]
        top_signals[1,top] = 1
        top = fo_importance.argsort()[-1 * top_n:][::-1]
        top_signals[2,top] = 1

        for i in range(len(baselines)):
            for j in range(len(baselines)):
                matrix[i,j] = np.matmul(top_signals[i],top_signals[j])/float(top_n)
        sum_matrix += matrix

    sum_matrix = sum_matrix/count

    fig = plt.figure()
    ax = fig.add_subplot(111)
    cax = ax.matshow(sum_matrix, interpolation='nearest')
    cb = fig.colorbar(cax, norm=mpl.colors.Normalize(vmin=0.0, vmax=1.))

    ax.set_xticklabels(['']+baselines, fontsize=24)
    ax.set_yticklabels(['']+baselines, fontsize=24)
    fig.savefig('/scratch/gobi1/sana/accordance.pdf')


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--generator', type=str, default='joint_RNN_generator')
    parser.add_argument('--data_path', type=str, default='/scratch/gobi1/sana/TSX_results/')
    args = parser.parse_args()
    main(generator_type=args.generator, data_path=args.data_path)
